# BPNN
反向传播神经网络
## 1.引例
### 1.1数据说明
train.csv中包括约1000条的医疗账单数据，其中
| age | sex | bmi | children | smoker | region | charges |
| :----: | :----: | :----: | :----: | :----: | :----: | :----: |
| 45 | female | 25.175 | 2 | no | northeast | 9095.06825 |
| 19 | male | 31.92 | 0 | yes | northwest | 33750.2918 |  
###
**age**：年龄  
**sex**：性别，包括male和female  
**children**：孩子的数量  
**somker**：是否吸烟，yes表示吸烟，no表示不吸烟  
**region**：所属地区，包括northeast，northwest，southeast和southwest四个地区  
**charges**： 医疗费用  
基于上述未加粗属性（特征）构建模型预测charges属性  

### 1.2模型要求
使用pandas读取数据train.csv，自行决定数据的预处理方式
使用numpy构建全连接神经网络，自行决定模型结构
## 2.分析
### 2.1 数据预处理
将特征中的文本信息转化为数字编码  
对数据进行归一化或标准化，防止神经网络偏置
### 2.2 网络结构
### 2.3 反向传播算法
反向传播算法(Back propagation)是“误差反向传播”的简称，是适合于多层神经元网络的一种学习算法，它建立在梯度下降法的基础上。梯度下降法是训练神经网络的常用方法，许多的训练方法都是基于梯度下降法改良出来的，因此了解梯度下降法很重要。梯度下降法通过计算损失函数的梯度，并将这个梯度反馈给最优化函数来更新权重以最小化损失函数。

BP算法的学习过程由正向传播过程和反向传播过程组成。  
它的基本思想为：

(1)先计算每一层的状态和激活值，直到最后一层（即信号是前向传播的）；

(2)计算每一层的误差，误差的计算过程是从最后一层向前推进的（即误差是反向传播的）；

(3)计算每个神经元连接权重的梯度；

(4)根据梯度下降法则更新参数（目标是误差变小）。

迭代以上步骤，直到满足停止准则（比如相邻两次迭代的误差的差别很小）。
